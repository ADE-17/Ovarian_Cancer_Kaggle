{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1720223/3035528147.py:81: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_wo_tma['label'] = train_wo_tma['label'].map(label_mapping)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/home/woody/iwso/iwso092h/mad_ucb_kaggle')\n",
    "import pandas as pd\n",
    "import timm\n",
    "import os\n",
    "import torchvision.models as models\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "# from datasets import CustomCancerDataset\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import numpy as np\n",
    "mlb = MultiLabelBinarizer()\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from trainer import train_classification_model\n",
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image  \n",
    "from torchvision import transforms\n",
    "\n",
    "root = r'/home/woody/iwso/iwso092h/mad_ucb_kaggle'\n",
    "train_images = r'train_thumbnails'\n",
    "image_folder = r'/home/woody/iwso/iwso092h/mad_ucb_kaggle/train_thumbnails'\n",
    "\n",
    "class CustomCancerDataset(Dataset):\n",
    "    def __init__(self, metadata_df, image_folder, transform=None):\n",
    "        self.metadata_df = metadata_df\n",
    "        self.image_folder = image_folder\n",
    "        self.transform = transform  # Use the provided transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.metadata_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_ids = self.metadata_df.image_id[idx]  \n",
    "        image_name = os.path.join(self.image_folder, \"{}_thumbnail.png\".format(image_ids))\n",
    "        image = Image.open(image_name).convert('RGB')\n",
    "        label = int(self.metadata_df.label[idx])\n",
    "        # label_CC  = self.metadata_df.label_CC[idx].astype(int)  \n",
    "        # label_EC  = self.metadata_df.label_EC[idx].astype(int)    \n",
    "        # label_HGSC  = self.metadata_df.label_HGSC[idx].astype(int)    \n",
    "        # label_LGSC  = self.metadata_df.label_LGSC[idx].astype(int)    \n",
    "        # label_MC  = self.metadata_df.label_MC[idx].astype(int)    \n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "        # return image, torch.tensor([label_CC, label_EC, label_HGSC, label_LGSC, label_MC], dtype=torch.float)\n",
    "        \n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        pt = torch.exp(-nn.CrossEntropyLoss(reduction='none')(inputs, targets))\n",
    "        loss = (1 - pt) ** self.gamma * nn.CrossEntropyLoss(reduction='none')(inputs, targets)\n",
    "        if self.alpha is not None:\n",
    "            loss = loss * self.alpha\n",
    "        if self.reduction == 'mean':\n",
    "            return loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return loss.sum()\n",
    "        else:\n",
    "            return loss\n",
    "\n",
    "train_df = pd.read_csv(os.path.join(root,'data','train.csv'))\n",
    "train_wo_tma = train_df[train_df.is_tma==False]\n",
    "label_mapping = {'HGSC': 0, 'LGSC': 1, 'EC': 2, 'CC': 3, 'MC': 4}\n",
    "train_wo_tma['label'] = train_wo_tma['label'].map(label_mapping)\n",
    "train_split, val_split = train_test_split(train_wo_tma, test_size=0.2, random_state=17, stratify=train_wo_tma.label)\n",
    "train_split = train_split.reset_index(drop=True)\n",
    "val_split = val_split.reset_index(drop=True)\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),# Color jitter\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.48828688, 0.42932517, 0.49162089], std=[0.41380908, 0.37492874, 0.41795654])\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.48828688, 0.42932517, 0.49162089], std=[0.41380908, 0.37492874, 0.41795654])\n",
    "])\n",
    "\n",
    "train_ucb_dataset = CustomCancerDataset(train_split, image_folder='/home/woody/iwso/iwso092h/mad_ucb_kaggle/train_thumbnails',\n",
    "                                  transform=train_transforms)\n",
    "val_ucb_dataset = CustomCancerDataset(val_split, image_folder='/home/woody/iwso/iwso092h/mad_ucb_kaggle/train_thumbnails',\n",
    "                                  transform=val_transforms)\n",
    "\n",
    "# class_weights = {0: 0.46067416, 1: 2.48484848, 2: 0.82828283, 3: 1.15492958, 4: 2.82758621}\n",
    "# sample_weights = [class_weights[label] for _, label in train_ucb_dataset]\n",
    "\n",
    "# sampler = WeightedRandomSampler(sample_weights, len(sample_weights), replacement=True)\n",
    "\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_ucb_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_ucb_dataset, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/woody/iwso/iwso092h/miniconda/lib/python3.11/site-packages/timm/models/_factory.py:114: UserWarning: Mapping deprecated model name tf_efficientnetv2_s_in21ft1k to current tf_efficientnetv2_s.in21k_ft_in1k.\n",
      "  model = create_fn(\n"
     ]
    }
   ],
   "source": [
    "num_classes = 5  \n",
    "learning_rate = 0.01\n",
    "step_size = 3\n",
    "gamma = 0.1  \n",
    "num_epochs = 10\n",
    "########################################\n",
    "\n",
    "# resnet_model = models.resnet34(pretrained=True)\n",
    "# in_features = resnet_model.fc.in_features\n",
    "# resnet_model.fc = nn.Linear(in_features, num_classes)\n",
    "model = UBCModel('efficient_net',num_classes=5)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "scheduler = StepLR(optimizer, step_size=step_size, gamma=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "running_loss = 0.0\n",
    "total_samples = 0\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "\n",
    "for inputs, labels in tqdm(train_loader, leave=False):\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    running_loss += loss.item()\n",
    "\n",
    "    all_labels.extend(labels.cpu().numpy())\n",
    "    all_predictions.extend(torch.argmax(outputs, 1).cpu().numpy())\n",
    "\n",
    "    total_samples += labels.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                             \r"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "running_loss = 0.0\n",
    "total_samples = 0\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in tqdm(val_loader, leave=False):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_predictions.extend(torch.argmax(outputs, 1).cpu().numpy())\n",
    "\n",
    "        total_samples += labels.size(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeM(nn.Module):\n",
    "    def __init__(self, p=3, eps=1e-6):\n",
    "        super(GeM, self).__init__()\n",
    "        self.p = nn.Parameter(torch.ones(1)*p)\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gem(x, p=self.p, eps=self.eps)\n",
    "        \n",
    "    def gem(self, x, p=3, eps=1e-6):\n",
    "        return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1./p)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + \\\n",
    "                '(' + 'p=' + '{:.4f}'.format(self.p.data.tolist()[0]) + \\\n",
    "                ', ' + 'eps=' + str(self.eps) + ')'\n",
    "                \n",
    "class UBCModel(nn.Module):\n",
    "    def __init__(self, model_name, num_classes, pretrained=False, checkpoint_path=None):\n",
    "        super(UBCModel, self).__init__()\n",
    "        self.model = timm.create_model('tf_efficientnetv2_s_in21ft1k', pretrained=pretrained)\n",
    "\n",
    "        in_features = self.model.classifier.in_features\n",
    "        self.model.classifier = nn.Identity()\n",
    "        self.model.global_pool = nn.Identity()\n",
    "        self.pooling = GeM()\n",
    "        self.linear = nn.Linear(in_features, num_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, images):\n",
    "        features = self.model(images)\n",
    "        pooled_features = self.pooling(features).flatten(1)\n",
    "        output = self.linear(pooled_features)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
